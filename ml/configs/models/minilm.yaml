model:
  name: microsoft/MiniLM-L12-H384-uncased
  max_length: 128

paths:
  output_dir: artifacts/experiments/minilm_v1
  
training:
  learning_rate: 2e-5
  train_batch_size: 32
  eval_batch_size: 32
  num_epochs: 12
  weight_decay: 0.01
  seed: 42
  warmup_ratio: 0.06
  label_smoothing_factor: 0.05

evaluation:
  eval_batch_size: 128
