{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "845f0e54",
   "metadata": {},
   "source": [
    "# Emotion Dataset\n",
    "\n",
    "This notebook performs a lightweight exploration of the `dair-ai/emotion` dataset. Its purpose is to understand the data schema, labels, and text characteristics before training.\n",
    "\n",
    "This notebook intentionally excludes any model training or evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f234633",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "912406b6",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5b9a7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q datasets transformers pandas\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d416f5",
   "metadata": {},
   "source": [
    "## Load & Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c213ad0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 16000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 2000\n",
      "    })\n",
      "})\n",
      "1. {'text': 'i didnt feel humiliated', 'label': 0}\n",
      "2. {'text': 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake', 'label': 0}\n",
      "3. {'text': 'im grabbing a minute to post i feel greedy wrong', 'label': 3}\n",
      "4. {'text': 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property', 'label': 2}\n",
      "5. {'text': 'i am feeling grouchy', 'label': 3}\n"
     ]
    }
   ],
   "source": [
    "# Load the emotion dataset\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "print(dataset)\n",
    "\n",
    "# Display first 5 samples from the training set\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}.\", dataset[\"train\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c95c3",
   "metadata": {},
   "source": [
    "## Label Names & Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "36001d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sadness     4666\n",
       "joy         5362\n",
       "love        1304\n",
       "anger       2159\n",
       "fear        1937\n",
       "surprise     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "print(\"Label names:\", label_names)\n",
    "\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "label_counts = df[\"label\"].value_counts().sort_index()\n",
    "label_counts.index = [label_names[i] for i in label_counts.index]\n",
    "\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e336124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         0.335125\n",
       "sadness     0.291625\n",
       "anger       0.134937\n",
       "fear        0.121063\n",
       "love        0.081500\n",
       "surprise    0.035750\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display the proportion of each label in the training set\n",
    "split_counts = (\n",
    "    dataset[\"train\"].to_pandas()[\"label\"].value_counts(normalize=True)\n",
    ")\n",
    "\n",
    "split_counts.index = [label_names[i] for i in split_counts.index]\n",
    "split_counts.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fccba7",
   "metadata": {},
   "source": [
    "The dataset is moderately imbalanced, which is typical for emotion datasets.\n",
    "For model evaluation, metrics such as macro-F1 are more informative than accuracy alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab13255",
   "metadata": {},
   "source": [
    "## Token Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bedd503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16000.000000\n",
       "mean        20.259500\n",
       "std         11.575801\n",
       "min          2.000000\n",
       "25%         11.000000\n",
       "50%         18.000000\n",
       "75%         27.000000\n",
       "max         85.000000\n",
       "Name: token_length, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate token lengths using DistilBERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\", use_fast=True)\n",
    "\n",
    "df[\"token_length\"] = df[\"text\"].apply(\n",
    "    lambda x: len(tokenizer.tokenize(x))\n",
    ")\n",
    "\n",
    "df[\"token_length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143296d",
   "metadata": {},
   "source": [
    "Most samples are short:\n",
    "- 75% of samples are under ~30 tokens\n",
    "- Even the longest samples stay under 100 tokens\n",
    "\n",
    "This suggests that a `max_length` of 64 or 128 is good enough for transformer-based models without excessive padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0f1ef8",
   "metadata": {},
   "source": [
    "## Insights\n",
    "\n",
    "- Use a transformer-based sentence classifier due to short, context-dependent text.\n",
    "- Limit maximum sequence length to reduce padding and improve efficiency.\n",
    "- Account for class imbalance during evaluation using macro-averaged metrics.'\n",
    "\n",
    "These insights were implemented in `ml/training/train.py`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
